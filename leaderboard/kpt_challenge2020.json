[{"description": " See <a href=\"https://s3-us-west-1.amazonaws.com/presentations.cocodataset.org/ECCV20/keypoints/UDP.pdf\">technical report</a>. ","leaderboard_name": "kpt-challenge2020","url": "https://github.com/HuangJunJie2017/UDP-Pose","results": "{\"AP\": \"0.774\", \"AP_50\": \"0.935\", \"AP_75\": \"0.838\", \"AP_medium\": \"0.718\", \"AP_large\": \"0.847\", \"AR\": \"0.826\", \"AR_50\": \"0.963\", \"AR_75\": \"0.883\", \"AR_medium\": \"0.775\", \"AR_large\": \"0.894\"}","results_details": {"ensemble": true, "external_data": true},"leaderboard_id": 25,"team": {"id": 1286, "members": "Junjie Huang*, Zengguang Shan*, Yuanhao Cai*, Feng Guo, Yun Ye and Xinze Chen (XForwardAI Technology, * indicates equal contribution), Zheng Zhu (Tsinghua University), Guan Huang (XForwardAI Technology), Jiwen Lu (Tsinghua University), Dalong Du (XForwardAI Technology)", "name": "XForwardAI"},"date": "2020-08-23","publication": ""},{"description": "We use a two stage top-down method. In the first stage, we use DetectoRS to detect human bounding boxes. In the second stage, we use Structured Fusion Network (SFNetv2) to detect human keypoints. Finally we use Refinement Network to refine the results by using ensemble method with 6 models. Our best single model has 0.775 of mAP on COCO test-dev dataset, and final result has 0.781 of mAP on COCO test-dev dataset and 0.755 of mAP on COCO test-challenge dataset. See <a href=\"https://s3-us-west-1.amazonaws.com/presentations.cocodataset.org/ECCV20/keypoints/SFNet.pdf\">technical report</a>.", "leaderboard_name": "kpt-challenge2020", "url": "", "results": "{\"AP\": \"0.755\", \"AP_50\": \"0.917\", \"AP_75\": \"0.817\", \"AP_medium\": \"0.704\", \"AP_large\": \"0.833\", \"AR\": \"0.809\", \"AR_50\": \"0.953\", \"AR_75\": \"0.866\", \"AR_medium\": \"0.758\", \"AR_large\": \"0.877\"}","results_details": {"ensemble": true, "external_data": true},"leaderboard_id": 25,"team": {"id": 1287, "members": "Li Yanjun; Zhifan Li; Jia Wei", "name": "Netease"},"date": "2020-08-23","publication": ""}, {"description": "This paper is the technical report of team ReferAlgo for COCO Keypoint Challenge 2020. We follow the top-down paradigm in this contest, which firstly applies detectoRS to detect persons from given images, and then estimates keypoints of detected human bodies with HRNet-based methods. Our best single model achieved AP score of 77.8 on COCO test-dev dataset, and the performance of our ensembled methods reached 78.3 on COCO test-dev dataset and 75.9 on COCO test-challenge dataset respectively. See <a href=\"https://s3-us-west-1.amazonaws.com/presentations.cocodataset.org/ECCV20/keypoints/ReferAlgo.pdf\">technical report</a>.", "leaderboard_name": "kpt-challenge2020","url": "","results": "{\"AP\": \"0.759\", \"AP_50\": \"0.920\", \"AP_75\": \"0.820\", \"AP_medium\": \"0.709\", \"AP_large\": \"0.836\", \"AR\": \"0.811\", \"AR_50\": \"0.953\", \"AR_75\": \"0.867\", \"AR_medium\": \"0.761\", \"AR_large\": \"0.879\"}","results_details": {"ensemble": true, "external_data": true},"leaderboard_id": 25,"team": {"id": 1288, "members": "Min Du (Horizon Robotics); Kun Zhang (Institute of Computing Technology, Chinese Academy of Sciences); Yuhao Dou (Horizon Robotics); Rui Wu (Horizon Robotics)", "name": "ReferAlgo"},"date": "2020-08-23","publication": ""}]
