<h1>Data format</h1>
<p>COCO has several annotation types: for <a href="#detection-2020">object detection</a>, <a href="#keypoints-2020">keypoint detection</a>, <a href="#stuff-2019">stuff segmentation</a>, <a href="#panoptic-2020">panoptic segmentation</a>, <a href="#densepose-2020">densepose</a>, and <a href="#captions-2015">image captioning</a>. The annotations are stored using <a href="http://json.org/" target="_blank">JSON</a>. Please note that the <a href="https://github.com/cocodataset/cocoapi" target="_blank">COCO API</a> described on the <a href="#download">download</a> page can be used to access and manipulate all anotations. All annotations share the same basic data structure below:</p>
<div class="json">
  <div class="jsonreg">{</div>
  <div class="jsonk">"info"           </div><div class="jsonv">: info,</div>
  <div class="jsonk">"images"         </div><div class="jsonv">: [image],</div>
  <div class="jsonk">"annotations"    </div><div class="jsonv">: [annotation],</div>
  <div class="jsonk">"licenses"       </div><div class="jsonv">: [license],</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">info{</div>
  <div class="jsonk">"year"           </div><div class="jsonv">: int,</div>
  <div class="jsonk">"version"        </div><div class="jsonv">: str,</div>
  <div class="jsonk">"description"    </div><div class="jsonv">: str,</div>
  <div class="jsonk">"contributor"    </div><div class="jsonv">: str,</div>
  <div class="jsonk">"url"            </div><div class="jsonv">: str,</div>
  <div class="jsonk">"date_created"   </div><div class="jsonv">: datetime,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">image{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"width"          </div><div class="jsonv">: int,</div>
  <div class="jsonk">"height"         </div><div class="jsonv">: int,</div>
  <div class="jsonk">"file_name"      </div><div class="jsonv">: str,</div>
  <div class="jsonk">"license"        </div><div class="jsonv">: int,</div>
  <div class="jsonk">"flickr_url"     </div><div class="jsonv">: str,</div>
  <div class="jsonk">"coco_url"       </div><div class="jsonv">: str,</div>
  <div class="jsonk">"date_captured"  </div><div class="jsonv">: datetime,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">license{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"name"           </div><div class="jsonv">: str,</div>
  <div class="jsonk">"url"            </div><div class="jsonv">: str,</div>
  <div class="jsonreg">}</div>
</div>
<p>The data structures specific to the various annotation types are described below.</p>

<h1>1. Object Detection</h1>
<p>Each object instance annotation contains a series of fields, including the category id and segmentation mask of the object. The segmentation format depends on whether the instance represents a single object (iscrowd=0 in which case polygons are used) or a collection of objects (iscrowd=1 in which case RLE is used). Note that a single object (iscrowd=0) may require multiple polygons, for example if occluded. Crowd annotations (iscrowd=1) are used to label large groups of objects (e.g. a crowd of people). In addition, an enclosing bounding box is provided for each object (box coordinates are measured from the top left image corner and are 0-indexed). Finally, the categories field of the annotation structure stores the mapping of category id to category and supercategory names. See also the <a href="#detection-2020">detection</a> task.</p>
<div class="json">
  <div class="jsonreg">annotation{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"image_id"       </div><div class="jsonv">: int,</div>
  <div class="jsonk">"category_id"    </div><div class="jsonv">: int,</div>
  <div class="jsonk">"segmentation"   </div><div class="jsonv">: RLE or [polygon],</div>
  <div class="jsonk">"area"           </div><div class="jsonv">: float,</div>
  <div class="jsonk">"bbox"           </div><div class="jsonv">: [x,y,width,height],</div>
  <div class="jsonk">"iscrowd"        </div><div class="jsonv">: 0 or 1,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">categories[{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"name"           </div><div class="jsonv">: str,</div>
  <div class="jsonk">"supercategory"  </div><div class="jsonv">: str,</div>
  <div class="jsonreg">}]</div>
</div>

<h1>2. Keypoint Detection</h1>
<p>A keypoint annotation contains all the data of the object annotation (including id, bbox, etc.) and two additional fields. First, "keypoints" is a length 3k array where k is the total number of keypoints defined for the category. Each keypoint has a 0-indexed location x,y and a visibility flag v defined as v=0: not labeled (in which case x=y=0), v=1: labeled but not visible, and v=2: labeled and visible. A keypoint is considered visible if it falls inside the object segment. "num_keypoints" indicates the number of labeled keypoints (v>0) for a given object (many objects, e.g. crowds and small objects, will have num_keypoints=0). Finally, for each category, the categories struct has two additional fields: "keypoints," which is a length k array of keypoint names, and "skeleton", which defines connectivity via a list of keypoint edge pairs and is used for visualization. Currently keypoints are only labeled for the person category (for most medium/large non-crowd person instances). See also the <a href="#keypoints-2020">keypoint</a> task.</p>
<div class="json">
  <div class="jsonreg">annotation{</div>
  <div class="jsonk">"keypoints"        </div><div class="jsonv">: [x1,y1,v1,...],</div>
  <div class="jsonk">"num_keypoints"    </div><div class="jsonv">: int,</div>
  <div class="jsonk">"[cloned]"         </div><div class="jsonv">: ...,</div>
  <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">categories[{</div>
  <div class="jsonk">"keypoints"        </div><div class="jsonv">: [str],</div>
  <div class="jsonk">"skeleton"         </div><div class="jsonv">: [edge],</div>
  <div class="jsonk">"[cloned]"         </div><div class="jsonv">: ...,</div>
  <div class="jsonreg">}]</div>
  <br/>
  <div>"[cloned]": denotes fields copied from object detection annotations defined above.</div>
</div>

<h1>3. Stuff Segmentation</h1>
<p>The stuff annotation format is identical and fully compatible to the object detection format above (except iscrowd is unnecessary and set to 0 by default). We provide annotations in both JSON and png format for easier access, as well as <a href="https://github.com/nightrome/coco">conversion scripts</a> between the two formats. In the JSON format, each category present in an image is encoded with a single RLE annotation (see the Mask API for more details). The category_id represents the id of the current stuff category. For more details on stuff categories and supercategories see the <a href="#stuff-eval">stuff evaluation</a> page. See also the <a href="#stuff-2019">stuff</a> task.</p>

<h1>4. Panoptic Segmentation</h1>
<p>For the <a href="#panoptic-2020">panoptic</a> task, each annotation struct is a <i>per-image annotation</i> rather than a per-object annotation. Each per-image annotation has two parts: (1) a PNG that stores the <i>class-agnostic image segmentation</i> and (2) a JSON struct that stores the <i>semantic information</i> for each image segment. In more detail:</p>
<ol>
  <li>To match an annotation with an image, use the <span class="fontMono">image_id</span> field (that is <span class="fontMono">annotation.image_id==image.id</span>).</li>
  <li>For each annotation, per-pixel segment ids are stored as a single PNG at <span class="fontMono">annotation.file_name</span>. The PNGs are in a folder with the same name as the JSON, i.e., <span class="fontMono">annotations/name/</span> for <span class="fontMono">annotations/name.json</span>. Each segment (whether it's a stuff or thing segment) is assigned a unique id. Unlabeled pixels (void) are assigned a value of 0. Note that when you load the PNG as an RGB image, you will need to compute the <span class="fontMono">ids</span> via <span class="fontMono">ids=R+G*256+B*256^2</span>.</li>
  <li>For each annotation, per-segment info is stored in <span class="fontMono">annotation.segments_info</span>. <span class="fontMono">segment_info.id</span> stores the unique id of the segment and is used to retrieve the corresponding mask from the PNG (<span class="fontMono">ids==segment_info.id</span>). <span class="fontMono">category_id</span> gives the semantic category and <span class="fontMono">iscrowd</span> indicates the segment encompasses a group of objects (relevant for thing categories only). The <span class="fontMono">bbox</span> and <span class="fontMono">area</span> fields provide additional info about the segment.</li>
  <li>The COCO panoptic task has the same thing categories as the detection task, whereas the stuff categories differ from those in the stuff task (for details see the <a href="#panoptic-eval">panoptic evaluation</a> page). Finally, each category struct has two additional fields: <span class="fontMono">isthing</span> that distinguishes stuff and thing categories and <span class="fontMono">color</span> that is useful for consistent visualization.</li>
</ol><br/>
<div class="json">
  <div class="jsonreg">annotation{</div>
    <div class="jsonk">"image_id"         </div><div class="jsonv">: int,</div>
    <div class="jsonk">"file_name"        </div><div class="jsonv">: str,</div>
    <div class="jsonk">"segments_info"    </div><div class="jsonv">: [segment_info],</div>
    <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">segment_info{</div>
    <div class="jsonk">"id"               </div><div class="jsonv">: int,</div>.
    <div class="jsonk">"category_id"      </div><div class="jsonv">: int,</div>
    <div class="jsonk">"area"             </div><div class="jsonv">: int,</div>
    <div class="jsonk">"bbox"             </div><div class="jsonv">: [x,y,width,height],</div>
    <div class="jsonk">"iscrowd"          </div><div class="jsonv">: 0 or 1,</div>
    <div class="jsonreg">}</div>
  <br/>
  <div class="jsonreg">categories[{</div>
  <div class="jsonk">"id"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"name"           </div><div class="jsonv">: str,</div>
  <div class="jsonk">"supercategory"  </div><div class="jsonv">: str,</div>
  <div class="jsonk">"isthing"        </div><div class="jsonv">: 0 or 1,</div>
  <div class="jsonk">"color"          </div><div class="jsonv">: [R,G,B],</div>
  <div class="jsonreg">}]</div>
</div>

<h1>5. Image Captioning</h1>
<p>These annotations are used to store image captions. Each caption describes the specified image and each image has at least 5 captions (some images have more). See also the <a href="#captions-2015">captioning</a> task.</p>
<div class="json">
  <div class="jsonreg">annotation{</div>
  <div class="jsonk">"id"               </div><div class="jsonv">: int,</div>
  <div class="jsonk">"image_id"         </div><div class="jsonv">: int,</div>
  <div class="jsonk">"caption"          </div><div class="jsonv">: str,</div>
  <div class="jsonreg">}</div>
</div>

<h1>6. DensePose</h1>
<p>For the <a href="#densepose-2020">DensePose</a> task, each annotation contains a series of fields, including category id, bounding box, body part masks and parametrization data for selected points, which are detailed below.</p>
<p>Crowd annotations (<span class="fontMono">iscrowd=1</span>) are used to label large groups of objects (e.g. a crowd of people).</p>
<p>An enclosing bounding box is provided for each person (box coordinates are measured from the top left image corner and are 0-indexed).</p>
<p>The categories field of the annotation structure stores the mapping of category id to category and supercategory names.</p>
<p>DensePose annotations are stored in <span class="fontMono">dp_*</span> fields:</p>
<p><em>Annotated masks</em>:</p>
<ul>
<li><span class="fontMono">dp_masks</span>: RLE encoded dense masks. All part masks are of size 256x256.
They correspond to 14 semantically meaningful parts of the body: <span class="fontMono">Torso</span>,
<span class="fontMono">Right Hand</span>, <span class="fontMono">Left Hand</span>, <span class="fontMono">Left Foot</span>, <span class="fontMono">Right Foot</span>, <span class="fontMono">Upper Leg Right</span>,
<span class="fontMono">Upper Leg Left</span>, <span class="fontMono">Lower Leg Right</span>, <span class="fontMono">Lower Leg Left</span>, <span class="fontMono">Upper Arm Left</span>,
<span class="fontMono">Upper Arm Right</span>, <span class="fontMono">Lower Arm Left</span>, <span class="fontMono">Lower Arm Right</span>, <span class="fontMono">Head</span>;</li>
</ul>
<p><em>Annotated points</em>:</p>
<ul>
<li><span class="fontMono">dp_x</span>, <span class="fontMono">dp_y</span>: spatial coordinates of collected points on the image.
The coordinates are scaled such that the bounding box size is 256x256;</li>
<li><span class="fontMono">dp_I</span>: The patch index that indicates which of the 24 surface patches the
point is on. Patches correspond to the body parts described above. Some
body parts are split into 2 patches: <span class="fontMono">1, 2 = Torso</span>, <span class="fontMono">3 = Right Hand</span>,
<span class="fontMono">4 = Left Hand</span>, <span class="fontMono">5 = Left Foot</span>, <span class="fontMono">6 = Right Foot</span>, <span class="fontMono">7, 9 = Upper Leg Right</span>,
<span class="fontMono">8, 10 = Upper Leg Left</span>, <span class="fontMono">11, 13 = Lower Leg Right</span>, <span class="fontMono">12, 14 = Lower Leg Left</span>,
<span class="fontMono">15, 17 = Upper Arm Left</span>, <span class="fontMono">16, 18 = Upper Arm Right</span>, <span class="fontMono">19, 21 = Lower Arm Left</span>,
<span class="fontMono">20, 22 = Lower Arm Right</span>, <span class="fontMono">23, 24 = Head</span>;</li>
<li><span class="fontMono">dp_U</span>, <span class="fontMono">dp_V</span>: Coordinates in the UV space. Each surface patch has a
separate 2D parameterization.</li>
</ul>
<div class="json">
  <div class="jsonreg">annotation{</div>
  <div class="jsonk">"id"               </div><div class="jsonv">: int,</div>
  <div class="jsonk">"image_id"         </div><div class="jsonv">: int,</div>
  <div class="jsonk">"category_id"      </div><div class="jsonv">: int,</div>
  <div class="jsonk">"is_crowd"          </div><div class="jsonv">: 0 or 1,</div>
  <div class="jsonk">"area"             </div><div class="jsonv">: int,</div>
  <div class="jsonk">"bbox"             </div><div class="jsonv">: [x,y,width,height],</div>
  <div class="jsonk">"dp_I"             </div><div class="jsonv">: [float],</div>
  <div class="jsonk">"dp_U"             </div><div class="jsonv">: [float],</div>
  <div class="jsonk">"dp_V"             </div><div class="jsonv">: [float],</div>
  <div class="jsonk">"dp_x"             </div><div class="jsonv">: [float],</div>
  <div class="jsonk">"dp_y"             </div><div class="jsonv">: [float],</div>
  <div class="jsonk">"dp_masks"             </div><div class="jsonv">: [RLE],</div>
  <div class="jsonreg">}</div>
</div>
