<h1>COCO 2018 Panoptic Segmentation Task</h1>
<p><img src="images/panoptic-challenge-splash.png" class="wide"/></p>

<h1>1. Overview</h1>
<p>We are pleased to introduce the COCO Panoptic Segmentation Task with the goal of advancing the state of the art in scene segmentation. Panoptic segmentation addresses both stuff and thing class, unifying the typically distinct semantic and instance segementation tasks. The aim is to generate coherent scene segmentations that are rich and complete, an important step toward real-world vision systems such as in autonomous driving or augmented reality. For full details of the panoptic segmentation task please see the <a href="#panoptic-eval">panoptic evaluation</a> page.</p>
<p>In a bit more detail: things are countable objects such as people, animals, tools. Stuff classes are amorphous regions of similar texture or material such as grass, sky, road. Previous COCO tasks addressed stuff and thing classes separately, see the <a href="#detections-challenge2018">instance segmentation</a> and <a href="#stuff-challenge2018">stuff segmentation</a> tasks, respectively. To encourage the study of stuff and things in a unified framework, we introduce the COCO Panoptic Segmentation Task. The definition of 'panoptic' is "including everything visible in one view", in our context panoptic refers to a unified, global view of segmentation. The panoptic segmentation task involves assigning a semantic label and instance id for each pixel of an image, which requires generating dense, coherent scene segmentations. The stuff annotations for this task come from the <a href="https://github.com/nightrome/cocostuff">COCO-Stuff project</a> described in this <a href="https://arxiv.org/abs/1612.03716">paper</a>. For more details about the panoptic task, including evaluation metrics, please see the <a href="https://arxiv.org/abs/1801.00868">panoptic segmentation paper</a>.</p>
<p>The panoptic segmentation task is part of the <a href="workshop/coco-mapillary-eccv-2018.html">Joint COCO and Mapillary Recognition Challenge Workshop</a> at ECCV 2018. For further details about the joint workshop please visit the workshop website. Researchers are encouraged to participate in both the COCO and Mapillary Panoptic Segmentation Tasks (the tasks share identical data formats and evaluation metrics). Please also see the related COCO <a href="#detections-challenge2018">detection</a>, <a href="#keypoints-challenge2018">keypoint</a>, and <a href="#stuff-challenge2018">stuff</a> tasks.</p>
<p>The panoptic task uses all the annotated COCO images and includes the 80 thing categories from the <a href="#detections-challenge2018">detection</a> task and 91 stuff categories from the <a href="#stuff-challenge2018">stuff</a> task, with any overlaps resolved. The Panoptic Quality (PQ) metric is used for performance evaluation, for details see the <a href="#panoptic-eval">panoptic evaluation</a> page. <b>More details coming soon.</b></p>
<p><b>Note: annotations, evaluation code, and further details for panoptic segmentation will be available in May. The evaluation server will be live a bit later. We appreciate your patience as we complete development and testing.</b></p>

<h1>2. Dates</h1>
<div class="json">
  <div class="jsonktxt fontBlue">August 10, 2018</div><div class="jsonvtxt">Submission deadline (11:59 PST)</div>
  <div class="jsonktxt">August 26, 2018</div><div class="jsonvtxt">Challenge winners notified</div>
  <div class="jsonktxt">September 9, 2018</div><div class="jsonvtxt">Winners present at ECCV 2018 Workshop</div>
</div>

<h1>3. Organizers</h1>
<div>Alex Kirillov (Heidelberg, Facebook AI Research)</div>
<div>Tsung-Yi Lin (Google Brain)</div>
<div>Holger Caesar (U. of Edinburgh)</div>
<div>Ross Girshick (Facebook AI Research)</div>
<div>Piotr Doll√°r (Facebook AI Research)</div>

<h1>4. Award Committee</h1>
<div>Genevieve Patterson (MSR, Trash TV)</div>
<div>Matteo Ruggero Ronchi (Caltech)</div>
<div>Yin Cui (Cornell Tech)</div>
<div>Holger Caesar (U. of Edinburgh)</div>
<div>Jasper Uijlings (Google)</div>
<div>Vittorio Ferrari (Google, U. of Edinburgh)</div>
<div>Michael Maire (TTI-Chicago)</div>
<div>Serge Belongie (Cornell Tech)</div>
<div>Lubomir Bourdev (WaveOne, Inc.)</div>
<div>James Hays (Georgia Tech)</div>
<div>Pietro Perona (Caltech)</div>
<div>Deva Ramanan (CMU)</div>

<h1>5. Task Guidelines</h1>
TBA

<h1>6. Tools and Instructions</h1>
TBA
